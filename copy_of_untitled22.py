# -*- coding: utf-8 -*-
"""Copy of Untitled22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12S2_iuPxzsGLVjfYhom58HUK4hMEbqo1
"""

import cv2
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import MobileNetV2
import os

def apply_custom_filter(image_path):
    img = cv2.imread(image_path.decode())
    img = cv2.resize(img, (224, 224))

    bilateral = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)

    laplacian = cv2.Laplacian(bilateral, cv2.CV_64F)
    laplacian = cv2.convertScaleAbs(laplacian)


    lab = cv2.cvtColor(laplacian, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0)
    cl = clahe.apply(l)
    lab_enhanced = cv2.merge((cl, a, b))
    enhanced_lab = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2RGB)

    def apply_gabor(img_gray):
        gabor_filtered = np.zeros_like(img_gray)
        for theta in np.arange(0, np.pi, np.pi / 4):
            kernel = cv2.getGaborKernel((21, 21), 4.0, theta, 10.0, 0.5, 0, ktype=cv2.CV_32F)
            filtered = cv2.filter2D(img_gray, cv2.CV_8UC3, kernel)
            gabor_filtered = np.maximum(gabor_filtered, filtered)
        return gabor_filtered

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gabor = apply_gabor(gray)
    gabor_color = cv2.merge([gabor, gabor, gabor])

    hybrid = cv2.addWeighted(enhanced_lab, 0.6, gabor_color, 0.4, 0)

    return hybrid.astype(np.uint8)

def process_and_label(file_path, label):
    img = tf.numpy_function(apply_custom_filter, [file_path], tf.uint8)
    img.set_shape((224, 224, 3))
    img = tf.image.convert_image_dtype(img, tf.float32)
    return img, label

import shutil

for folder in ['train', 'validation', 'test']:
    checkpoints_path = f'paddy_dataset/{folder}/.ipynb_checkpoints'
    if os.path.exists(checkpoints_path):
        shutil.rmtree(checkpoints_path)


train = ImageDataGenerator(rescale=1/255)
validation = ImageDataGenerator(rescale=1/255)

train_dataset = train.flow_from_directory("paddy_dataset/train",
                                          target_size=(200,200),
                                          batch_size=16,
                                          class_mode='sparse')
validation_dataset = train.flow_from_directory("paddy_dataset/validation",
                                          target_size=(200,200),
                                          batch_size=16,
                                          class_mode='sparse')

num_classes=len(train_dataset.class_indices)

base_model = tf.keras.applications.MobileNetV2(
    input_shape=(200, 200, 3),
    include_top=False,
    weights='imagenet'
)

base_model.trainable = True

fine_tune_at = 100
for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False

model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(num_classes, activation='softmax')
])

model.compile(loss='sparse_categorical_crossentropy',
              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-5),
              metrics=['accuracy'])

from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.callbacks import EarlyStopping

checkpoint_cb = ModelCheckpoint("best_finetuned_model.h5", save_best_only=True)
fine_tune_epochs = 10

history=model.fit(train_dataset,
          epochs=fine_tune_epochs,
          validation_data=validation_dataset,
          callbacks=[EarlyStopping(patience=2, restore_best_weights=True), checkpoint_cb])

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(1, len(acc) + 1)

plt.figure(figsize=(8, 6))
plt.plot(epochs, acc, 'bo-', label='Training Accuracy')
plt.plot(epochs, val_acc, 'go-', label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

dir_path = 'paddy_dataset/test'
class_labels = list(train_dataset.class_indices.keys())

for file_name in os.listdir(dir_path):
    file_path = os.path.join(dir_path, file_name)


    if not os.path.isfile(file_path) or not file_name.lower().endswith(('.png', '.jpg', '.jpeg')):
        continue


    img = image.load_img(file_path, target_size=(200, 200))
    plt.imshow(img)
    plt.axis('off')
    plt.show()


    X = image.img_to_array(img)
    X = np.expand_dims(X, axis=0)
    X = X / 255.0

    val = model.predict(X)
    predicted_class = np.argmax(val)

    print(f"Predicted Class: {class_labels[predicted_class]}")

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score
import numpy as np
import seaborn as sns

y_true = []
y_pred = []

for batch_images, batch_labels in validation_dataset:
    preds = model.predict(batch_images)
    predicted_labels = np.argmax(preds, axis=1)

    y_true.extend(batch_labels)
    y_pred.extend(predicted_labels)

    if len(y_true) >= validation_dataset.samples:
        break

y_true = np.array(y_true[:validation_dataset.samples])
y_pred = np.array(y_pred[:validation_dataset.samples])
cm = confusion_matrix(y_true, y_pred)

cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

class_labels = validation_dataset.class_names if hasattr(validation_dataset, 'class_names') else [str(i) for i in range(cm.shape[0])]



plt.figure(figsize=(14, 10))
sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Greens', xticklabels=class_labels, yticklabels=class_labels)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()


print("\nClassification Report:")
print(classification_report(y_true, y_pred))

print("\nAccuracy Score:", accuracy_score(y_true, y_pred))
print("Precision Score:", precision_score(y_true, y_pred, average='macro'))
print("Recall Score:", recall_score(y_true, y_pred, average='macro'))